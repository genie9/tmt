univers algorithm agent aixi activ system like game play sg optim fm cannot reduc induct system main idea work general univers induct general agent model describ section general includ action condit replac ration agent model result ai aixi model way problem true prior probabl usual unknown solv converg shown indic ai model could behav optim comput unknown environ reinforc feedback main focus section investig expect univers optim agent clarifi mean univers optim etc unfortun bound similar loss bound sp case hold activ agent forc us lower expect univers optim agent introduc weaker perform measur final show ai pareto optim sens polici yield higher equal valu environ strict higher valu least one univers ai model ai model univers ai model model univers model ai definit ai model develop enough formal suggest univers ai model suitabl general univers semimeasur last section replac true unknown prior probabl ai model general sens ai model univers discuss subsequ universalgener priorgener univers prior function formul defin univers probabl environ mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muth definit could easierit necessari use someth similar reader may expect point everi program exist function equival program later identifi object code relat fix ture machin exampl function binari code revers alreadi binari string defin collect formula section replac get definit ai agent function form given histori polici function ai agent given mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muin cycl total reward cycl agent interact environ drop denomin independ constant multipl factor chang iter formul univers probabl obtain insert function mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mureplac iter ai agent output mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muin cycl given histori equival function iter ai model theorem true everi chronolog semimeasur especi henc talk ai model respect slight depend choic univers ture machin defin addit constant ai model also depend choic expect bias space chosen suffici simpl e g string length bias choos word space would ideal whether maxima suprema exist case shown beforehand nontrivi depend horizon function discuss later apart unimport detail ai agent uniqu defin depend assumpt environ apart generat comput unknown probabl distribut converg similar one show expect squar differ finit comput turn show converg rapid probabl line reason pure spectat chang analyz loss reward bound analog general one show thather everywher els mean converg limit valu mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muthi give hope output ai model could converg output ai model solvabl problem problem solvabl learnabl task task learnabl univers optim optim univers want call ai model univers independ unbias model free abl solv solvabl problem learn learnabl task call univers model univers optim program solv learn signific faster term interact cycl inde ai model paramet free converg ai model optim expect model converg faster ai analog sp claim expect aixi univers optim main claim sens intent remain section defin statement rigor give support intellig order relat intelligenceord relationord relationintelligenceconsistentpolicypolicyconsistentinconsistentpolicypolicyinconsistentw defin expect reward cycl polici similar extend definit program consist current histori mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muth normal necessari interpret expect reward otherwis unneed consist polici defin modif way output consist current histori henc unalt current futur cycl use definit could take maximium polici rather consist one definit intellig order relat call polici equal intellig write mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mui e yield circumst higher expect reward intellig agent agent intellig univers order relat order relat univers intermedi intellig intellig intermedi algorithm behind ai agent maxim ai model henc intellig agent w r relat univers order relat sens free paramet except specif assumpt environ proof reliabl intellig order believ true would prove ai univers optim could ask use order polici practic interest intermedi intellig help guid toward construct intellig system reason comput time effect intellig order relat defin section use practic point view optim aixi optim ai model ai model optim adapt control control adapt section outlin way toward optim proof aixi sourc inspir sp loss bound proven section optim criteria adapt control literatur main linear system valu bound aixi expect sens weaker sp loss bound problem class cover aixi much larger class induct problem converg alreadi proven suffici establish converg behavior aixi model behavior ai model focus three approach toward general optim proof univers optim optim univers meant univers optim first step investig expect aixi e meant univers optim “learner” like aixi may converg optim inform decis maker like ai sever sens possibl relev concept statist consistencyconsist self tunabilityself tunabl self optimizationself optim efficiencyeffici unbiasednessunbiased asymptot asymptoticconvergenceconvergenceasymptoticfiniteconvergenceconvergencefinitefinit converg pareto optim defin section pareto optim concept stronger necessari other weaker desir suitabl start self optim defin asymptot converg averag true valu ai optim valu apart converg speed self optim aixi would close correspond loss bound proven sp investig properti desir circumst aixi model satisfi properti show univers model includ aixi general self optim hand show aixi pareto optim sens polici perform better equal environ strict better least one limit environment class environment class limit restrict concept class concept class restrict limit environment class problem defin prove general valu bound becom feasibl consid first step restrict concept class analyz aixi known class like markovian factoriz environ especi new class forget relev asymptot learnabl farsight uniform pseudo passiv passiv defin later section section studi behavior aixi various standard problem class includ sequenc predict strateg game function minim supervis learn general bay mixtur bay mixtur general general bay mixtur ai model ai model general bay mixtur general aixi general bay mixtur approach general aixi ai general bay mixtur distribut class multi set enumer semimeasur enumer ture machin ai coincid aixi multi set passiv effect environ aixi reduc predictor shown perform well one show loss valu bound general wider class least asymptot promis class one describ section particular ergod mdps show ai self optim obvious least must demand self optimizingpolicypolicyself optim chanc find self optim polici exist self optim polici key result necessari condit also suffici general key prove absolut result specif problem class prove relat result form “if exist polici certain desir properti ai also possess desir properties” task cannot solv polici ai cannot blame fail environment class allow self optim polici includ bandit process classif task certain class pomdp order ergod mdps factoriz environ repeat game predict problem note approach environment class correspond model ai wherea approach pursu articl univers aixi model analyz environment class optim construct bandit problem optim construct possibl approach toward optim “proof” regard aixi optim construct perspect common various simpler set instanc bandit problem pull arm lead reward unknown probabl tradit bayesian solut uncertainti assum uniform beta prior maxim subject expect reward sum multipl trial exact solut term gittin indic wide regard “optimal” although justifi altern approach exist similar simpler assum uniform subject prior bernoulli paramet one arriv reason controversi laplac rule predict sequenc aixi similar sens unknown analogu unknown prior belief justifi occam razor analogu uniform distribut sens gittin solut bandit problem laplac rule bernoulli sequenc aixi may also regard optim construct theorem relat aixi ai would regard optim proof aixi much harder becom oper unknown e achiev first three approach simpli reinterpret valu bound separ concept valu bound bound valu separ concept concept separ introduct valu associ ai system correspond rough negat loss sp system sp interest small bound loss excess unfortun simpl valu bound ai term analog loss bound hold even difficulti specifi expect hold ai ai system claim univers optim consequ cannot proof know prove sp import properti prove loss bound complex see ai case use bound term either studi restrict problem class consid bound depend properti rather complex follow exhibit difficulti two exampl introduc concept may use prove valu bound despit difficulti even claim use valu bound nevertheless firm believ order relat definit correct formal intuit mean intellig henc ai agent univers optim pseudo passiv heavenhel exampl pseudo passiveenvironmentenvironmentpseudo passiveheavenhel examplein follow choos want compar true e expect valu independ univers polici polici naiv might expect exist polici maxim apart addit correct lower order mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus musuch polici sometim call self optim note candid univers depend hand polici ai agent maxim definit thought guess might expect approxim maxim e hold let us consid problem class set environ environ kroneck symbol defin otherwis first action decid whether go heaven futur reward good hell futur reward bad note determinist non ergod mdps hell start heaven clear e known optim polici output first cycl hand unbias polici independ actual either output independ actual choic alway environ choic catastroph singl agent perform well environ r h equal l h zero shown satisfi cannot expect nevertheless problem class hold instanc sp sp reformul appropri choic name differ see next section expect hold induct problem environ influencedof cours reward feedback depend agent output mind like sequenc predict true sequenc influenc agent output agent want call passiveenvironmentenvironmentpassiveinductiveenvironmentenvironmentinductivepseudo passiveenvironmentenvironmentpseudo passiv passiv induct environ want call satisfi pseudo passiv expect induct pseudo passiv onlyon exampl onlyon exampl let us give exampl demonstr difficulti establish valu bound let larg consid determinist environ singl complex output correct other wrong problem class defin mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muther way independ polici find correct tri one certain order first cycl differ test differ possibl alway give erron output first cycl number error true also true ai model henc best possibl error bound expect depend actual deriv bound section induct environ unfortun main interest cycl region see section bound vacuous interest bound determinist depend unlik sp case bound must either depend addit properti consid special bound restrict problem class case probabilist similar wherea sp use bound term bound ai drawback ai sinc unbias ai system could error reward bound term error reward ai poster bound boost boost bound way make use gross e g bound assum reason number cycl inform perceiv ai agent contain lot inform true environ inform might code form let us assum complex condit known order consid theorem bound sum reward quantiti cycl term function like bound cycl term henc bound like replac small bound cycl one show ensur assum enough inform present form first cycl way even gross bound could becom use section use similar argument prove ai abl learn supervis asymptot learnabl asymptoticlearnabilitylearnableasymptoticallyin follow weaken hope get bound applic wider problem class passiv one consid sequenc caus ai histori ai output cycl let us compar ai would output still histori produc ai ai maxim expect valu ai caus lower best equal differ let expect number suboptim choic ai e output differ ai first cycl one might weigh deviat case sever particular expect reward equal close taken account definit e g weight factor detail matter follow qualit discuss import differ suboptimaldecisiondecisionsuboptimaldecisionwrong stick histori produc ai count wrong decis one error wrong decis heavenhel exampl first cycl longer count lose reward count one wrong decis sens fairer one blame somebodi much make singl wrong decis littl inform avail order make correct decis ai model would deserv call asymptot optim probabl make wrong decis tend zero e mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus mu mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muw say asymptot learn ai satisfi claim ai asymptot learn everi problem relev e ai asymptot optim includ qualifi relevantproblemproblemrelevantof relev sure whether could strang spoil expect irrelev perspect ai field learn mani asymptot learnabl theorem often difficult prove proof might also feasibl unfortun asymptot learnabl theorem often weak use practic point view nevertheless point right direct uniform uniformenvironmentenvironmentuniform converg might expect henc might also expect defin converg defin first problem differ choic near equal even possibl due non continu cure weight describ serious second problem explain converg suffici know proven need converg true output also altern output converg converg uniform e addit mu mu plus mu minus mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muuniformconvergenceconvergenceuniform mu mu mu plus mu minus mu mu plus mu minus mu mu plus mu mu plus mu minus muhold constant least expect sens call satisfi uniform uniform one show appropri weight bound horizon unfortun relev uniform concept markovenvironmentenvironmentmarkovmarkov th orderfactorizableenvironmentenvironmentfactorizablestationaryenvironmentenvironmentstationaryforgetfulenvironmentenvironmentforgetfulfarsightedenvironmentenvironmentfarsightedin follow briefli mention concept markovian defin depend last cycl e say general order markovian fix properti similar factoriz defin call stationari call forget becom independ fix probabl say farsight exist detail given section also give exampl farsight nevertheless limit make sens summari introduc sever concept might use prove valu bound includ forget relev asymptot learnabl farsight uniform general markovian factoriz pseudo passiv sort approxim order decreas general call separ concept general like relev asymptot learnabl farsight call weak separ restrict like pseudo passiv factoriz call strong separ use qualifi qualit rather rigid sens non separ concept determinist cours class chronolog pareto optim ai model ai model pareto optim pareto optim ai subsect show pareto opimt ai analog sp total expect reward polici ai model central interest judg perform ai know polici e g ai higher valu general everi polici base estim closer outperform environ simpli tailor toward hand system probabl perform wors environ sinc know advanc may ask whether exist polici better equal perform environ strict better perform one would clear render suboptim one show definit pareto optim polici call pareto optim polici strict inequ least one theorem pareto optim ai alia pareto optim pareto optim regard necessari condit agent aim optim practic point view signific increas mani environ may desir even caus small decreas imposs “balanced” improv demand condit pure pareto optim shown ai also balanc pareto optim choic horizon horizon problem problem horizon signific arbitrari ai model lie choic horizon function discuss choic seem natur give preliminari conclus end discuss ad hoc choic specif problem like discuss section context finit strateg game interest univers choic fix horizon horizon fix fix horizon lifetim agent known practic alway larg finit choic maxim correct expect futur reward lifetim usual known advanc mani case time will run agent depend qualiti output reason often desir good output delay much result margin reward increas incorpor damp futur reward instanc probabl surviv cycl exponenti damp geometr discount appropri bound e g express converg case precis exist solv problem introduc new arbitrari time scale everi damp introduc time scale take prone problem undiscount case discuss dynam horizon horizon dynam univers discount discount univers harmon discount discount harmon dynam horizon univers harmon discount largest horizon guarante finit enumer reward sum obtain univers discount discount result truli farsight agent effect horizon grow faster comput function similar near harmon discount sinc general time scale invari damp factor introduc dynam time scale cycl contribut cycl damp factor effect horizon case choic qualit model behavior introduc arbitrari time scale limit farsighted multipl fraction length current histori avoid preselect global time scale choic appeal seem human age year usual plan live perhap next year practic point view model might serv need theoret point feel uncomfort limit horizon begin note choos otherwis would introduc number justifi favor univers discount sinc allow us desir “mimic” greedi behavior base discount choos infinit horizon horizon infinit infinit horizon naiv limit may turn well defin previous discuss superflu follow suggest limit alway well defin finit let defin depend made explicit let set output cycl choic defin model output best output consist arbitrari larg choic choos lexicograph smallest would correspond lower limit alway exist finit general uniqu e iff naiv limit exist note limit need exist construct averag reward reward averag differenti gain gain differenti averag reward differenti gain take raw averag reward also help consid arbitrari polici first cycl optim polici remain cycl e g environ limit exist polici give averag valu sinc chang finit number term affect infinit averag mdp environ singl recurr class one defin relat differenti gain general environ interest differenti gain infinit accept sinc differenti gain still total order major problem exist differenti gain e whether converg oscil old converg problem slight differ form immort agent agent immort lazi agent agent lazi immort agent lazi construct next previous paragraph lead mathemat eleg paramet ai model unfortun end stori limit caus undesir result ai model special might also happen ai model whatev defin consid agent everi consecut day work thereaft take day holiday formal consid output shall give reward output shall give iff e agent achiev consecut posit reward preced sequenc length least lifetim ai agent output first cycl remain cycl lead highest possibl total reward fragment sequenc would reduc e g altern work day take day would give ai agent delay point switch indefinit alway output lead total reward obvious worst possibl behavior ai agent explor rule tri appli behavior ai agent sinc simplest rule cover past data domin finit exact want infinit ai model probabl fail ai model good point weak ai model particular ai fail bad point far reach consequ even start alreadi larg exampl high nonloc time e may violat one weak separ condit conclus sure whether choic margin import long chosen suffici larg low complex instanc whether choic turn central topic ai model plan aspect ai system general suppos limit ai model result correct behavior weak separ proof conjectur true would probabl give interest insight outlook predict expert advic expert advic predict expert advic approach consid expect perform bound predict base solomonoff prior dual current popular approach “predict expert advice” pea invent littleston warmuth vovk wherea pea perform well environ relat given set expert predictor compet predictor expect environ comput distribut seem philosoph less compromis make assumpt predict strategi environ howev weak one could investig whether pea general case activ agent would result model dual aixi believ answer negat posit side would show necess occam razor assumpt distinguished aixi random action action random action random variabl uniqu choic general aixi model could explor origin mani altern could rule one altern still seem possibl instead defin one could treat agent action also univers distribut random variabl condition chain rule structur ai model ai model structur axiomat approach ai model ai model axiomat approach structur aixi algebra properti structur aixi could investig depth would extract essenti aixi final could lead axiomat character aixi benefit axiomat approach would clear exhibit assumpt separ essenti technic simplifi understand import guid find proof polici restrict class restrict polici class develop section could scale restrict class polici one may defin instanc consid finit class quick comput polici mdps quick comput effici comput mont carlo sampl maxim finit mani polici mont carlo select asymptot best polici ergod mdps conclus task requir intellig solv natur formul maxim expect util framework agent gave explicit express decis theoret agent main remain problem unknown prior probabl distribut environ convent learn algorithm unsuit neither handl larg unstructur state space converg theoret minim number cycl handl non stationari environ appropri hand univers semimeasur base idea algorithm inform theori solv problem unknown prior distribut induct problem explicit learn procedur necessari automat converg unifi theori univers sequenc predict decis theoret agent replac unknown true prior appropri general univers semimeasur gave strong argument result ai model univers optim furthermor possibl solut horizon problem discuss section present number problem class outlin ai model solv includ sequenc predict strateg game function minim especi ai learn learn supervis section develop modifi time bound comput aixi version
